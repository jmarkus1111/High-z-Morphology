{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating the background light ... ... ...\n",
      "The negative PSF values are corrected as 0 values.\n",
      "The data_process is ready to go to pass to FittingSpecify!\n",
      "The settings for the fitting is done. Ready to pass to FittingProcess. \n",
      "  However, please make updates manullay if needed.\n",
      "MCMC selected. Sampling with default option emcee.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:27<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the MCMC...\n",
      "Number of walkers =  100\n",
      "Burn-in iterations:  100\n",
      "Sampling iterations (in current run): 130\n",
      "27.909294843673706 time taken for MCMC sampling\n",
      "MCMC selected. Sampling with default option emcee.\n",
      "re-using previous samples to initialize the next MCMC run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:51<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the MCMC...\n",
      "Number of walkers =  100\n",
      "Burn-in iterations:  100\n",
      "Sampling iterations (in current run): 300\n",
      "51.58700156211853 time taken for MCMC sampling\n",
      "79.567 total time taken for the overall fitting (s)\n",
      "============ CONGRATULATION, YOUR JOB WAS SUCCESSFUL ================ \n",
      "Start transfering the Params to fluxs...\n",
      "10000 MCMC samplers in total, finished translate: 0\n",
      "10000 MCMC samplers in total, finished translate: 1000\n",
      "10000 MCMC samplers in total, finished translate: 2000\n",
      "10000 MCMC samplers in total, finished translate: 3000\n",
      "10000 MCMC samplers in total, finished translate: 4000\n",
      "10000 MCMC samplers in total, finished translate: 5000\n",
      "10000 MCMC samplers in total, finished translate: 6000\n",
      "10000 MCMC samplers in total, finished translate: 7000\n",
      "10000 MCMC samplers in total, finished translate: 8000\n",
      "10000 MCMC samplers in total, finished translate: 9000\n",
      "Residual sum:  1.5279896201753143\n"
     ]
    }
   ],
   "source": [
    "import os, glob, corner, sys\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import astropy.coordinates\n",
    "from astropy.io import fits\n",
    "import webbpsf\n",
    "import subprocess\n",
    "from galight.data_process_Danial import DataProcess\n",
    "from galight.fitting_specify_Danial import FittingSpecify\n",
    "from galight.fitting_process_Danial import FittingProcess\n",
    "\n",
    "def galight_free_mod(object, filter, save_dir, nsigma, npixels, fit_bulge=True):\n",
    "\n",
    "    # config\n",
    "    program_ID = object.split('_')[0]\n",
    "    object_ID = object.split('_')[1]\n",
    "    save_path = f'{save_dir}/{program_ID}/{object_ID}'\n",
    "\n",
    "    pixelscale = 0.04\n",
    "\n",
    "    # read the data\n",
    "\n",
    "    # reading the fits_files\n",
    "    psf_file = f'{save_path}/{filter}_{pixelscale}.fits'\n",
    "    PSF_data = fits.open(psf_file)[0].data\n",
    "    \n",
    "    sci_file = glob.glob(f'{save_path}/*{object_ID}*sci*')[0]\n",
    "    sci_data = fits.open(sci_file)[0].data\n",
    "\n",
    "    wht_file = glob.glob(f'{save_path}/*{object_ID}*wht*')[0]\n",
    "    wht_data = fits.open(wht_file)[0].data\n",
    "    err_data = np.power(wht_data, -0.5)\n",
    "\n",
    "    # calculate the photometric zero point\n",
    "    sci_header = fits.open(sci_file)[0].header\n",
    "    zeropoint = 28.9\n",
    "    # zeropoint = -2.5 * np.log10(sci_header['PHOTFLAM']) - 5 * np.log10(sci_header['PHOTPLAM']) - 2.408\n",
    "    \n",
    "\n",
    "    # the main target is at the centre of the FOV\n",
    "    x_target, y_target = int(sci_data.shape[0]/2), int(sci_data.shape[1]/2)\n",
    "\n",
    "    # run GALIGHT\n",
    "\n",
    "    # GALIGHT pre-processing step\n",
    "    data_process = DataProcess(fov_image=sci_data, fov_noise_map=err_data, header=sci_header,\n",
    "                               target_pos=[x_target, y_target], pos_type='pixel',\n",
    "                               rm_bkglight=True, if_plot=False, zp=zeropoint)\n",
    "\n",
    "    radius = 1.2/pixelscale # arcsec/arcsec\n",
    "    data_process.generate_target_materials(radius=radius, create_mask=False, if_plot=False,\n",
    "                                           nsigma=nsigma, exp_sz=1.5, npixels=npixels,\n",
    "                                           detect=True, detection_path=save_path)\n",
    "\n",
    "    # add the PSF\n",
    "    data_process.PSF_list = [PSF_data]\n",
    "\n",
    "    # check if everything is there before attempting the run\n",
    "    data_process.checkout()\n",
    "\n",
    "    # fit bulge separately if specified with fit_bulge\n",
    "    if fit_bulge == True:\n",
    "        # modify the fitting of the component (i.e., galaxy) id = 0 into to components (i.e., bulge + disk)\n",
    "        import copy\n",
    "        apertures = copy.deepcopy(data_process.apertures)\n",
    "        comp_id = 0 \n",
    "        add_aperture0 = copy.deepcopy(apertures[comp_id])\n",
    "        # this setting assigns comp0 as 'bulge' and comp1 as 'disk'\n",
    "        add_aperture0.a, add_aperture0.b = add_aperture0.a/2, add_aperture0.b/2\n",
    "        apertures = apertures[:comp_id] + [add_aperture0] + apertures[comp_id:]\n",
    "        data_process.apertures = apertures # pass apertures to the data_process\n",
    "\n",
    "        # adding a prior so that 1)the size of the bulge is within a range to the disk size, 2) disk have more ellipticity\n",
    "        import lenstronomy.Util.param_util as param_util\n",
    "        def condition_bulgedisk(kwargs_lens, kwargs_source, kwargs_lens_light, kwargs_ps, kwargs_special, kwargs_extinction, kwargs_tracer_source):\n",
    "            logL = 0\n",
    "            # note that the Comp[0] is the bulge and the Comp[1] is the disk\n",
    "            phi0, q0 = param_util.ellipticity2phi_q(kwargs_lens_light[0]['e1'], kwargs_lens_light[0]['e2'])\n",
    "            phi1, q1 = param_util.ellipticity2phi_q(kwargs_lens_light[1]['e1'], kwargs_lens_light[1]['e2'])\n",
    "            cond_0 = (kwargs_lens_light[0]['R_sersic'] > kwargs_lens_light[1]['R_sersic'] * 0.9)\n",
    "            cond_1 = (kwargs_lens_light[0]['R_sersic'] < kwargs_lens_light[1]['R_sersic']*0.15)\n",
    "            cond_2 = (q0 < q1)\n",
    "            if cond_0 or cond_1 or cond_2:\n",
    "                logL -= 10**15\n",
    "            return logL\n",
    "\n",
    "    # set up the model\n",
    "    fit_sepc = FittingSpecify(data_process)\n",
    "    # the 'fix_n_list' will fix Sersic_n as 4 for the comp0 (bulge), and as 1 for the comp1 (disk).\n",
    "    fit_sepc.prepare_fitting_seq(point_source_num = 0, fix_n_list= [[0,4], [1,1]]) \n",
    "    fit_sepc.build_fitting_seq()\n",
    "    # fit_sepc.plot_fitting_sets()\n",
    "\n",
    "    # set up the fitting method and run\n",
    "    savename = f'{save_path}/galight_{filter}'\n",
    "    fit_run = FittingProcess(fit_sepc, savename=savename, fitting_level=['shallow', 'deep'])\n",
    "    fit_run.run(algorithm_list = ['MCMC', 'MCMC'])\n",
    "\n",
    "\n",
    "\n",
    "    data = fit_run.fitting_specify_class.kwargs_data['image_data']\n",
    "    noise = fit_run.fitting_specify_class.kwargs_data['noise_map']\n",
    "    galaxy_list = fit_run.image_host_list\n",
    "    galaxy_image = np.zeros_like(galaxy_list[0])\n",
    "    for i in range(len(galaxy_list)):\n",
    "        galaxy_image = galaxy_image+galaxy_list[i]\n",
    "    model = galaxy_image\n",
    "    norm_residual = (data - model)/noise\n",
    "\n",
    "    # (data - central model) / central model\n",
    "    # TODO: only use central profile\n",
    "    norm_residual *= model # scale by sersic profile \n",
    "    return norm_residual\n",
    "\n",
    "\n",
    "object = '2750_9973'\n",
    "save_dir = '/Users/jmark/OneDrive/Desktop/DARK REU/morphology_fitting/saves'\n",
    "nsigma = 1.9\n",
    "npixels = 4\n",
    "\n",
    "norm_residual = galight_free_mod(object, 'SW', save_dir, nsigma, npixels)\n",
    "\n",
    "residual_sum = sum(map(sum, np.abs(norm_residual))) # sum absolute value of all elements of 2d array \n",
    "print('Residual sum: ', residual_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
